{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288d012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef21aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaaed0c6",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. \n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Atist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56be1a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views_in_Billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>10.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                 Video_Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                               Shape of You   \n",
       "4    5.                              See You Again   \n",
       "5    6.                                  Bath Song   \n",
       "6    7.  Learning Colors – Colorful Eggs on a Farm   \n",
       "7    8.   Masha and the Bear – Recipe for Disaster   \n",
       "8    9.                Phonics Song with Two Words   \n",
       "9   10.                                Uptown Funk   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.                             Dame Tu Cosita   \n",
       "12  13.                          Wheels on the Bus   \n",
       "13  14.                                      Sugar   \n",
       "14  15.                                       Roar   \n",
       "15  16.                                      Sorry   \n",
       "16  17.                             Counting Stars   \n",
       "17  18.                          Thinking Out Loud   \n",
       "18  19.                             Girls Like You   \n",
       "19  20.                                     Axel F   \n",
       "20  21.                                      Faded   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                                 Let Her Go   \n",
       "23  24.                                   Bailando   \n",
       "24  25.                                    Lean On   \n",
       "25  26.                               Shake It Off   \n",
       "26  27.                        Baa Baa Black Sheep   \n",
       "27  28.                                    Perfect   \n",
       "28  29.           Waka Waka (This Time for Africa)   \n",
       "29  30.                                   Mi Gente   \n",
       "\n",
       "                                    Artist_Name        Upload_Date  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                    Luis Fonsi   January 12, 2017   \n",
       "2                                   LooLoo Kids    October 8, 2016   \n",
       "3                                    Ed Sheeran   January 30, 2017   \n",
       "4                                   Wiz Khalifa      April 6, 2015   \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "6                                   Miroshka TV  February 27, 2018   \n",
       "7                                    Get Movies   January 31, 2012   \n",
       "8                                     ChuChu TV      March 6, 2014   \n",
       "9                                   Mark Ronson  November 19, 2014   \n",
       "10                                          Psy      July 15, 2012   \n",
       "11                                    El Chombo      April 5, 2018   \n",
       "12                   Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "13                                     Maroon 5   January 14, 2015   \n",
       "14                                   Katy Perry  September 5, 2013   \n",
       "15                                Justin Bieber   October 22, 2015   \n",
       "16                                  OneRepublic       May 31, 2013   \n",
       "17                                   Ed Sheeran    October 7, 2014   \n",
       "18                                     Maroon 5       May 31, 2018   \n",
       "19                                   Crazy Frog      June 16, 2009   \n",
       "20                                  Alan Walker   December 3, 2015   \n",
       "21                                   Katy Perry  February 20, 2014   \n",
       "22                                    Passenger      July 25, 2012   \n",
       "23                             Enrique Iglesias     April 11, 2014   \n",
       "24                                  Major Lazer     March 22, 2015   \n",
       "25                                 Taylor Swift    August 18, 2014   \n",
       "26                   Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "27                                   Ed Sheeran   November 9, 2017   \n",
       "28                                      Shakira       June 4, 2010   \n",
       "29                                     J Balvin      June 29, 2017   \n",
       "\n",
       "   Views_in_Billions  \n",
       "0              10.23  \n",
       "1               7.75  \n",
       "2               6.18  \n",
       "3               5.62  \n",
       "4               5.42  \n",
       "5               5.01  \n",
       "6               4.56  \n",
       "7               4.48  \n",
       "8               4.48  \n",
       "9               4.47  \n",
       "10              4.35  \n",
       "11              3.86  \n",
       "12              3.70  \n",
       "13              3.65  \n",
       "14              3.53  \n",
       "15              3.51  \n",
       "16              3.51  \n",
       "17              3.41  \n",
       "18              3.24  \n",
       "19              3.24  \n",
       "20              3.23  \n",
       "21              3.23  \n",
       "22              3.18  \n",
       "23              3.17  \n",
       "24              3.17  \n",
       "25              3.15  \n",
       "26              3.14  \n",
       "27              3.10  \n",
       "28              3.06  \n",
       "29              3.04  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "driver.find_element_by_xpath(\"//b\").click()\n",
    "records = []\n",
    "for row in driver.find_elements_by_xpath(\"(//table[@class='wikitable sortable jquery-tablesorter'])[1]//tr\")[1:-1]:\n",
    "    temp = ''\n",
    "    for element in row.find_elements_by_xpath(\".//td\"):        \n",
    "        temp += element.text + '|'\n",
    "    records.append(temp.split('|')[:-2])\n",
    "\n",
    "df = pd.DataFrame(records, columns=['Rank', 'Video_Name', 'Artist_Name', 'Views_in_Billions', 'Upload_Date'])\n",
    "\n",
    "arranged_cols = ['Rank', 'Video_Name', 'Artist_Name', 'Upload_Date', 'Views_in_Billions']\n",
    "\n",
    "df.Video_Name = df.Video_Name.apply(lambda x:x[:-4].strip('\"'))\n",
    "df = df[arranged_cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939612af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2505a947",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bab4b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 MAR 2022</td>\n",
       "      <td>India\\nvs\\nSri Lanka</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>4 MAR 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 MAR 2022</td>\n",
       "      <td>Pakistan Women\\nvs\\nIndia Women</td>\n",
       "      <td>Bay Oval,</td>\n",
       "      <td>6 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 MAR 2022</td>\n",
       "      <td>New Zealand Women\\nvs\\nIndia Women</td>\n",
       "      <td>Seddon Park,</td>\n",
       "      <td>10 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 MAR 2022</td>\n",
       "      <td>West Indies Women\\nvs\\nIndia Women</td>\n",
       "      <td>Seddon Park,</td>\n",
       "      <td>12 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 MAR 2022</td>\n",
       "      <td>India\\nvs\\nSri Lanka</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>12 MAR 2022</td>\n",
       "      <td>2:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16 MAR 2022</td>\n",
       "      <td>England Women\\nvs\\nIndia Women</td>\n",
       "      <td>Bay Oval,</td>\n",
       "      <td>16 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19 MAR 2022</td>\n",
       "      <td>India Women\\nvs\\nAustralia Women</td>\n",
       "      <td>Eden Park,</td>\n",
       "      <td>19 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22 MAR 2022</td>\n",
       "      <td>India Women\\nvs\\nBangladesh Women</td>\n",
       "      <td>Seddon Park,</td>\n",
       "      <td>22 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title                              Series  \\\n",
       "0   4 MAR 2022                India\\nvs\\nSri Lanka   \n",
       "1   6 MAR 2022     Pakistan Women\\nvs\\nIndia Women   \n",
       "2  10 MAR 2022  New Zealand Women\\nvs\\nIndia Women   \n",
       "3  12 MAR 2022  West Indies Women\\nvs\\nIndia Women   \n",
       "4  12 MAR 2022                India\\nvs\\nSri Lanka   \n",
       "5  16 MAR 2022      England Women\\nvs\\nIndia Women   \n",
       "6  19 MAR 2022    India Women\\nvs\\nAustralia Women   \n",
       "7  22 MAR 2022   India Women\\nvs\\nBangladesh Women   \n",
       "\n",
       "                                           Place         Date         Time  \n",
       "0  Punjab Cricket Association IS Bindra Stadium,   4 MAR 2022  9:30 AM IST  \n",
       "1                                      Bay Oval,   6 MAR 2022  6:30 AM IST  \n",
       "2                                   Seddon Park,  10 MAR 2022  6:30 AM IST  \n",
       "3                                   Seddon Park,  12 MAR 2022  6:30 AM IST  \n",
       "4                         M Chinnaswamy Stadium,  12 MAR 2022  2:30 PM IST  \n",
       "5                                      Bay Oval,  16 MAR 2022  6:30 AM IST  \n",
       "6                                     Eden Park,  19 MAR 2022  6:30 AM IST  \n",
       "7                                   Seddon Park,  22 MAR 2022  6:30 AM IST  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.bcci.tv/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "btn=driver.find_element_by_xpath(\"/html/body/nav/div/div[2]/ul[1]/li[2]/a\")\n",
    "btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Empty lists\n",
    "match_title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "matchtime=[]\n",
    "datetime=[]\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//h5[@class='ng-binding']\"):\n",
    "    match_title.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='fixture-card-mid d-flex align-items-center justify-content-between']\"):\n",
    "    series.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='ng-binding ng-scope']\"):\n",
    "    place.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='match-top-info d-flex align-items-center justify-content-between']\"):\n",
    "    datetime.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "date=[i.split(' ',3)[:3] for i in datetime]\n",
    "date=[' '.join(i) for i in date]\n",
    "matchtime=[i.split(' ',3)[-1] for i in datetime]\n",
    "\n",
    "print(len(match_title), len(series), len(place), len(date),len(matchtime))\n",
    "\n",
    "# Creating data frame\n",
    "matches_data=pd.DataFrame({'Match Title': match_title,\n",
    "                          \"Series\": series,\n",
    "                          \"Place\": place,\n",
    "                          \"Date\": date,\n",
    "                          \"Time\": matchtime})\n",
    "matches_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4efdaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da96dc4e",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e800ae1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception name</th>\n",
       "      <th>Exception description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can’t be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception name  \\\n",
       "0         ElementNotSelectableException   \n",
       "1                NoSuchElementException   \n",
       "2                  NoSuchFrameException   \n",
       "3               NoAlertPresentException   \n",
       "4                 NoSuchWindowException   \n",
       "5        StaleElementReferenceException   \n",
       "6              SessionNotFoundException   \n",
       "7                      TimeoutException   \n",
       "8                    WebDriverException   \n",
       "9             ConnectionClosedException   \n",
       "10     ElementClickInterceptedException   \n",
       "11      ElementNotInteractableException   \n",
       "12             ErrorInResponseException   \n",
       "13  ErrorHandler.UnknownServerException   \n",
       "14         ImeActivationFailedException   \n",
       "15             ImeNotAvailableException   \n",
       "16         InsecureCertificateException   \n",
       "17             InvalidArgumentException   \n",
       "18         InvalidCookieDomainException   \n",
       "19          InvalidCoordinatesException   \n",
       "20          InvalidElementStateExceptio   \n",
       "21            InvalidSessionIdException   \n",
       "22       InvalidSwitchToTargetException   \n",
       "23                  JavascriptException   \n",
       "24                        JsonException   \n",
       "25             NoSuchAttributeException   \n",
       "26       MoveTargetOutOfBoundsException   \n",
       "27               NoSuchContextException   \n",
       "28                NoSuchCookieException   \n",
       "29                    NotFoundException   \n",
       "30          RemoteDriverServerException   \n",
       "31                  ScreenshotException   \n",
       "32           SessionNotCreatedException   \n",
       "33           UnableToSetCookieException   \n",
       "34           UnexpectedTagNameException   \n",
       "35              UnhandledAlertException   \n",
       "36      UnexpectedAlertPresentException   \n",
       "37               UnknownMethodException   \n",
       "38          UnreachableBrowserException   \n",
       "39          UnsupportedCommandException   \n",
       "\n",
       "                                Exception description  \n",
       "0   This Selenium exception occurs when an element...  \n",
       "1   This Exception occurs if an element could not ...  \n",
       "2   This Exception occurs if the frame target to b...  \n",
       "3   This Exception occurs when you switch to no pr...  \n",
       "4   This Exception occurs if the window target to ...  \n",
       "5   This Selenium exception occurs happens when th...  \n",
       "6   The WebDriver is acting after you quit the bro...  \n",
       "7   Thrown when there is not enough time for a com...  \n",
       "8   This Exception takes place when the WebDriver ...  \n",
       "9   This type of Exception takes place when there ...  \n",
       "10  The command may not be completed as the elemen...  \n",
       "11  This Selenium exception is thrown when any ele...  \n",
       "12  This happens while interacting with the Firefo...  \n",
       "13  Exception is used as a placeholder in case if ...  \n",
       "14  This expectation will occur when IME engine ac...  \n",
       "15    It takes place when IME support is unavailable.  \n",
       "16  Navigation made the user agent to hit a certif...  \n",
       "17  It occurs when an argument does not belong to ...  \n",
       "18  This happens when you try to add a cookie unde...  \n",
       "19  This type of Exception matches an interacting ...  \n",
       "20  It occurs when command can’t be finished when ...  \n",
       "21  This Exception took place when the given sessi...  \n",
       "22  This occurs when the frame or window target to...  \n",
       "23  This issue occurs while executing JavaScript g...  \n",
       "24  It occurs when you afford to get the session w...  \n",
       "25  This kind of Exception occurs when the attribu...  \n",
       "26  It takes place if the target provided to the A...  \n",
       "27           ContextAware does mobile device testing.  \n",
       "28  This Exception occurs when no cookie matching ...  \n",
       "29  This Exception is a subclass of WebDriverExcep...  \n",
       "30  This Selenium exception is thrown when the ser...  \n",
       "31            It is not possible to capture a screen.  \n",
       "32  It happens when a new session could not be suc...  \n",
       "33  This occurs if a driver is unable to set a coo...  \n",
       "34  Happens if a support class did not get a web e...  \n",
       "35  This expectation occurs when there is an alert...  \n",
       "36  It occurs when there is the appearance of an u...  \n",
       "37  This Exception happens when the requested comm...  \n",
       "38  This Exception occurs only when the browser is...  \n",
       "39  This occurs when remote WebDriver does n’t sen...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.guru99.com/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "error = driver.find_element_by_xpath('//*[@id=\"java_technologies\"]/li[3]/a').get_attribute('href')\n",
    "driver.get(error)\n",
    "time.sleep(3)\n",
    "exception = driver.find_element_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div/table[5]/tbody/tr[34]/td[1]/a').get_attribute('href')\n",
    "driver.get(exception)\n",
    "\n",
    "Data = []\n",
    "table = driver.find_elements_by_xpath(\"//table[@class='table table-striped']//td\")\n",
    "for i in table:\n",
    "    try:\n",
    "        Data.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Data.append('-')\n",
    "\n",
    "Name = []\n",
    "for i in range(2,len(Data),2):\n",
    "    Name.append(Data[i])\n",
    "\n",
    "Description = []\n",
    "for i in range(3,len(Data),2):\n",
    "    Description.append(Data[i])\n",
    "\n",
    "df=pd.DataFrame({\"Exception name\": Name, \"Exception description\": Description})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6a2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8d95ce7",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP\n",
    "D) GSDP\n",
    "E) Share\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "428c71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.statisticstimes.com/economy/india-statistics.php\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "economy = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/button/i')\n",
    "economy.click()\n",
    "time.sleep(2)\n",
    "india = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "india.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35075784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP (Cr INR at Current prices) (19-20)</th>\n",
       "      <th>GSDP (Cr INR at Current prices) (18-19)</th>\n",
       "      <th>Share (18-19)</th>\n",
       "      <th>GDP ($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,391</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,424</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP (Cr INR at Current prices) (19-20)  \\\n",
       "0     1                Maharashtra                                       -   \n",
       "1     2                 Tamil Nadu                               1,845,853   \n",
       "2     3              Uttar Pradesh                               1,687,818   \n",
       "3     4                    Gujarat                                       -   \n",
       "4     5                  Karnataka                               1,631,977   \n",
       "..  ...                        ...                                     ...   \n",
       "61   29                     Sikkim                                  28,391   \n",
       "62   30                   Nagaland                                       -   \n",
       "63   31          Arunachal Pradesh                                       -   \n",
       "64   32                    Mizoram                                  24,424   \n",
       "65   33  Andaman & Nicobar Islands                                       -   \n",
       "\n",
       "   GSDP (Cr INR at Current prices) (18-19) Share (18-19) GDP ($ billion)  \n",
       "0                                2,632,792        13.94%         399.921  \n",
       "1                                1,630,208         8.63%         247.629  \n",
       "2                                1,584,764         8.39%         240.726  \n",
       "3                                1,502,899         7.96%         228.290  \n",
       "4                                1,493,127         7.91%         226.806  \n",
       "..                                     ...           ...             ...  \n",
       "61                                  25,141         0.15%          17,060  \n",
       "62                                  24,534         0.15%               -  \n",
       "63                                  22,488         0.13%               -  \n",
       "64                                  20,947         0.13%          17,797  \n",
       "65                                       -             -               -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_eco = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "ind_eco.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Empty lists\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2  = []\n",
    "Share = []\n",
    "GDP_billion = []\n",
    "\n",
    "try: # Scraping Rank\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"No such element present\")\n",
    "    \n",
    "try: # Scraping Name\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"No such element present\")\n",
    "    \n",
    "try: # Scraping GSDP1\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping GSDP2\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "\n",
    "try: # Scraping share\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")    \n",
    "    \n",
    "try: # Scraping GDP billion\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "# Creating data frame \n",
    "stats = pd.DataFrame({\"Rank\":Rank, \"State\":State, \"GSDP (Cr INR at Current prices) (19-20)\":GSDP1,\n",
    "                      \"GSDP (Cr INR at Current prices) (18-19)\":GSDP2, \"Share (18-19)\":Share, \n",
    "                      \"GDP ($ billion)\":GDP_billion})\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09fdaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "712aa968",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b43e0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39697235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almerico / bombardier</td>\n",
       "      <td>bombardier</td>\n",
       "      <td>37</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ministryofjustice / modernisation-platform</td>\n",
       "      <td>A place for the core work of the Modernisation...</td>\n",
       "      <td>86</td>\n",
       "      <td>HCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat-milk / Anime-Girls-Holding-Programming-Books</td>\n",
       "      <td>Anime Girls Holding Programming Books</td>\n",
       "      <td>475</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ytdl-org / youtube-dl</td>\n",
       "      <td>Command-line program to download videos from Y...</td>\n",
       "      <td>7,199</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AppFlowy-IO / AppFlowy</td>\n",
       "      <td>AppFlowy is an open-source alternative to Noti...</td>\n",
       "      <td>894</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MHProDev / MHDDoS</td>\n",
       "      <td>Best DDoS Attack Script Python3, Cyber Attack ...</td>\n",
       "      <td>393</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>palahsu / DDoS-Ripper</td>\n",
       "      <td>DDos Ripper a Distributable Denied-of-Service ...</td>\n",
       "      <td>110</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gkbrk / slowloris</td>\n",
       "      <td>Low bandwidth DoS tool. Slowloris rewrite in P...</td>\n",
       "      <td>535</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dj-nitehawk / FastEndpoints</td>\n",
       "      <td>A light-weight REST Api framework for ASP.Net ...</td>\n",
       "      <td>35</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cyprosecurity / API-SecurityEmpire</td>\n",
       "      <td>API Security Projecto aims to present unique a...</td>\n",
       "      <td>32</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Repository title  \\\n",
       "0                             almerico / bombardier   \n",
       "1        ministryofjustice / modernisation-platform   \n",
       "2  cat-milk / Anime-Girls-Holding-Programming-Books   \n",
       "3                             ytdl-org / youtube-dl   \n",
       "4                            AppFlowy-IO / AppFlowy   \n",
       "5                                 MHProDev / MHDDoS   \n",
       "6                             palahsu / DDoS-Ripper   \n",
       "7                                 gkbrk / slowloris   \n",
       "8                       dj-nitehawk / FastEndpoints   \n",
       "9                cyprosecurity / API-SecurityEmpire   \n",
       "\n",
       "                              Repository description Contributors count  \\\n",
       "0                                         bombardier                 37   \n",
       "1  A place for the core work of the Modernisation...                 86   \n",
       "2              Anime Girls Holding Programming Books                475   \n",
       "3  Command-line program to download videos from Y...              7,199   \n",
       "4  AppFlowy is an open-source alternative to Noti...                894   \n",
       "5  Best DDoS Attack Script Python3, Cyber Attack ...                393   \n",
       "6  DDos Ripper a Distributable Denied-of-Service ...                110   \n",
       "7  Low bandwidth DoS tool. Slowloris rewrite in P...                535   \n",
       "8  A light-weight REST Api framework for ASP.Net ...                 35   \n",
       "9  API Security Projecto aims to present unique a...                 32   \n",
       "\n",
       "  Language used  \n",
       "0         Shell  \n",
       "1           HCL  \n",
       "2        Python  \n",
       "3          Rust  \n",
       "4        Python  \n",
       "5        Python  \n",
       "6        Python  \n",
       "7            C#  \n",
       "8    JavaScript  \n",
       "9          Rust  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "explore.click()\n",
    "time.sleep(2)\n",
    "\n",
    "trending = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a\")\n",
    "trending.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Empty list\n",
    "Repository = []\n",
    "Repository_des = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "\n",
    "try: # Scraping repository\n",
    "    for i in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\"):\n",
    "        Repository.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Repository description\n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class='col-9 color-fg-muted my-1 pr-4']\"):\n",
    "        Repository_des.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "\n",
    "try: # Scraping Contributors count\n",
    "    for i in driver.find_elements_by_xpath(\"//*[@id='js-pjax-container']/div[3]/div/div[2]/article/div[2]/a[2]\"):\n",
    "        Contributors.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")   \n",
    "    \n",
    "try: # Scraping language\n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class='d-inline-block ml-0 mr-3']\"):\n",
    "        Language.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "\n",
    "# Creating data frame \n",
    "a = {\"Repository title\":Repository[:10],\"Repository description\":Repository_des[:10],\"Contributors count\": Contributors[:10],\"Language used\": Language[:10]}\n",
    "df = pd.DataFrame.from_dict(a, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a9ac2",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba370bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "Hot_song= driver.find_element_by_xpath(\"/html/body/div[4]/header/div[2]/div/nav/ul/li[1]/a\")\n",
    "Hot_song.click()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12e64d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>ArtistName</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>PeekPosition</th>\n",
       "      <th>Weeks On board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Don't Talk About Bruno</td>\n",
       "      <td>Carolina Gaitan, Mauro Castillo, Adassa, Rhenz...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Easy On Me</td>\n",
       "      <td>Adele</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abcdefu</td>\n",
       "      <td>GAYLE</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>All Too Well (Taylor's Version)</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Come Back As A Country Boy</td>\n",
       "      <td>Blake Shelton</td>\n",
       "      <td>83</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Iffy</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Home Sweet</td>\n",
       "      <td>Russell Dickerson</td>\n",
       "      <td>-</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Too Easy</td>\n",
       "      <td>Gunna &amp; Future</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SongName  \\\n",
       "0         We Don't Talk About Bruno   \n",
       "1                        Heat Waves   \n",
       "2                        Easy On Me   \n",
       "3                           abcdefu   \n",
       "4                              Stay   \n",
       "..                              ...   \n",
       "95  All Too Well (Taylor's Version)   \n",
       "96       Come Back As A Country Boy   \n",
       "97                             Iffy   \n",
       "98                       Home Sweet   \n",
       "99                         Too Easy   \n",
       "\n",
       "                                           ArtistName Last Week PeekPosition  \\\n",
       "0   Carolina Gaitan, Mauro Castillo, Adassa, Rhenz...                          \n",
       "1                                       Glass Animals         4            2   \n",
       "2                                               Adele         3            1   \n",
       "3                                               GAYLE         7            4   \n",
       "4                       The Kid LAROI & Justin Bieber         5            1   \n",
       "..                                                ...       ...          ...   \n",
       "95                                       Taylor Swift                          \n",
       "96                                      Blake Shelton        83           63   \n",
       "97                                        Chris Brown                          \n",
       "98                                  Russell Dickerson         -           83   \n",
       "99                                     Gunna & Future                          \n",
       "\n",
       "   Weeks On board  \n",
       "0                  \n",
       "1              57  \n",
       "2              19  \n",
       "3              13  \n",
       "4              32  \n",
       "..            ...  \n",
       "95                 \n",
       "96              6  \n",
       "97                 \n",
       "98              1  \n",
       "99                 \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrap all tags\n",
    "\n",
    "Name=[]\n",
    "Name.append(driver.find_element_by_xpath(\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\").text)\n",
    "Artist=[]\n",
    "Artist.append(driver.find_element_by_xpath(\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\").text)\n",
    "rank=[]\n",
    "rankTag=driver.find_elements_by_xpath(\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "rank.extend([i.text for i in rankTag[:3]])\n",
    "\n",
    "nameTag=driver.find_elements_by_xpath(\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Name.extend([i.text for i in nameTag])\n",
    "artistTag=driver.find_elements_by_xpath(\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Artist.extend([i.text for i in artistTag])\n",
    "Rank=[]\n",
    "RankTag=driver.find_elements_by_xpath(\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "Rank.extend([i.text for i in RankTag])\n",
    "\n",
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)\n",
    "        \n",
    "# slicing as per requirement\n",
    "lastweekpos=Rank[0::3]\n",
    "lastweekpos.insert(0,rank[0])\n",
    "peakPos=Rank[1::3]\n",
    "peakPos.insert(0,rank[1])\n",
    "weeksonBoard=Rank[2::3]\n",
    "weeksonBoard.insert(0,rank[2])\n",
    "\n",
    "#check length of all\n",
    "len(Name),len(Artist),len(lastweekpos),len(peakPos),len(weeksonBoard)\n",
    "df=pd.DataFrame()\n",
    "df['SongName']=Name\n",
    "df['ArtistName']=Artist\n",
    "df['Last Week']=lastweekpos[0:100]\n",
    "df[\"PeekPosition\"]=peakPos[0:100]\n",
    "df['Weeks On board']=weeksonBoard[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49828ac8",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e703626e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Job-designation</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>skill required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bachelors in Engineering, Computer Science, Ma...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSK India</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GSK India</td>\n",
       "      <td>Proven experience in successfully working in a...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSK India</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GSK India</td>\n",
       "      <td>The candidate will be required to interface wi...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Along with this, you will be expected to have ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Senior Data Analyst - FPG</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Along with this, you will be expected to have ...</td>\n",
       "      <td>Bangalore/Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KLENE PAKS LIMITED</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>KLENE PAKS LIMITED</td>\n",
       "      <td>Bachelors degree from an accredited university...</td>\n",
       "      <td>Bangalore/Bengaluru(Arekere)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Informatica</td>\n",
       "      <td>HR Data Analyst</td>\n",
       "      <td>Informatica</td>\n",
       "      <td>Bachelor s degree in Computer Science or Mathe...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Moody's</td>\n",
       "      <td>Financial Data Analyst - Mandarin Language</td>\n",
       "      <td>Moody's</td>\n",
       "      <td>Individual must be organized, dependable, able...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liventus</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Liventus</td>\n",
       "      <td>Bachelors degree in Management of Information ...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Experience in handling large data volumes. Str...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>Data Analyst - UNSPSC</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>Summary:As an Analyst, you will be required to...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Carrier</td>\n",
       "      <td>Specialist- Data Analyst- Machine Learning/Spo...</td>\n",
       "      <td>Carrier</td>\n",
       "      <td>This role calls for a data analyst, who will w...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Perficient India Private Limited</td>\n",
       "      <td>Data Analyst / SQL - Immediate To 15 days</td>\n",
       "      <td>Perficient India Private Limited</td>\n",
       "      <td>Location: Chennai &amp; Bangalore(Whitefield)Notic...</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yellow Box HR Services Pvt. Ltd.</td>\n",
       "      <td>Senior Data Analyst For a reputed E-Commerce C...</td>\n",
       "      <td>Yellow Box HR Services Pvt. Ltd.</td>\n",
       "      <td>Should have a keen eye for anomalies and data ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yellow Box HR Services Pvt. Ltd.</td>\n",
       "      <td>Senior Data Analyst For a reputed E-Commerce C...</td>\n",
       "      <td>Yellow Box HR Services Pvt. Ltd.</td>\n",
       "      <td>Should have a keen eye for anomalies and data ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Uber</td>\n",
       "      <td>Data Analyst II, Tech</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Experience with globalization &amp; aptitude to ex...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>About the role:Data Analyst is an Individual C...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hCapital Business Consulting Private Limited</td>\n",
       "      <td>Junior Data Analyst - Work From Home</td>\n",
       "      <td>hCapital Business Consulting Private Limited</td>\n",
       "      <td>Roles and Responsibilities Interpret data, ana...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>As a core activity they provide business insig...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CarePro Global</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CarePro Global</td>\n",
       "      <td>Knowledge of database query language (Redshift...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name  \\\n",
       "0                                       Flipkart   \n",
       "1                                      GSK India   \n",
       "2                                      GSK India   \n",
       "3                                       Flipkart   \n",
       "4                                       Flipkart   \n",
       "5                             KLENE PAKS LIMITED   \n",
       "6                                    Informatica   \n",
       "7                                        Moody's   \n",
       "8                                       Liventus   \n",
       "9                                       Flipkart   \n",
       "10                             SAP India Pvt.Ltd   \n",
       "11                                       Carrier   \n",
       "12              Perficient India Private Limited   \n",
       "13              Yellow Box HR Services Pvt. Ltd.   \n",
       "14              Yellow Box HR Services Pvt. Ltd.   \n",
       "15                                          Uber   \n",
       "16                                      Flipkart   \n",
       "17  hCapital Business Consulting Private Limited   \n",
       "18                               Thomson Reuters   \n",
       "19                                CarePro Global   \n",
       "\n",
       "                                      Job-designation  \\\n",
       "0                                 Senior Data Analyst   \n",
       "1                                        Data Analyst   \n",
       "2                                        Data Analyst   \n",
       "3                                 Senior Data Analyst   \n",
       "4                           Senior Data Analyst - FPG   \n",
       "5                                        Data Analyst   \n",
       "6                                     HR Data Analyst   \n",
       "7          Financial Data Analyst - Mandarin Language   \n",
       "8                                 Senior Data Analyst   \n",
       "9                                 Senior Data Analyst   \n",
       "10                              Data Analyst - UNSPSC   \n",
       "11  Specialist- Data Analyst- Machine Learning/Spo...   \n",
       "12          Data Analyst / SQL - Immediate To 15 days   \n",
       "13  Senior Data Analyst For a reputed E-Commerce C...   \n",
       "14  Senior Data Analyst For a reputed E-Commerce C...   \n",
       "15                              Data Analyst II, Tech   \n",
       "16                                       Data Analyst   \n",
       "17               Junior Data Analyst - Work From Home   \n",
       "18                                   Sr. Data Analyst   \n",
       "19                                       Data Analyst   \n",
       "\n",
       "                                    Company_name  \\\n",
       "0                                       Flipkart   \n",
       "1                                      GSK India   \n",
       "2                                      GSK India   \n",
       "3                                       Flipkart   \n",
       "4                                       Flipkart   \n",
       "5                             KLENE PAKS LIMITED   \n",
       "6                                    Informatica   \n",
       "7                                        Moody's   \n",
       "8                                       Liventus   \n",
       "9                                       Flipkart   \n",
       "10                             SAP India Pvt.Ltd   \n",
       "11                                       Carrier   \n",
       "12              Perficient India Private Limited   \n",
       "13              Yellow Box HR Services Pvt. Ltd.   \n",
       "14              Yellow Box HR Services Pvt. Ltd.   \n",
       "15                                          Uber   \n",
       "16                                      Flipkart   \n",
       "17  hCapital Business Consulting Private Limited   \n",
       "18                               Thomson Reuters   \n",
       "19                                CarePro Global   \n",
       "\n",
       "                                       skill required  \\\n",
       "0   Bachelors in Engineering, Computer Science, Ma...   \n",
       "1   Proven experience in successfully working in a...   \n",
       "2   The candidate will be required to interface wi...   \n",
       "3   Along with this, you will be expected to have ...   \n",
       "4   Along with this, you will be expected to have ...   \n",
       "5   Bachelors degree from an accredited university...   \n",
       "6   Bachelor s degree in Computer Science or Mathe...   \n",
       "7   Individual must be organized, dependable, able...   \n",
       "8   Bachelors degree in Management of Information ...   \n",
       "9   Experience in handling large data volumes. Str...   \n",
       "10  Summary:As an Analyst, you will be required to...   \n",
       "11  This role calls for a data analyst, who will w...   \n",
       "12  Location: Chennai & Bangalore(Whitefield)Notic...   \n",
       "13  Should have a keen eye for anomalies and data ...   \n",
       "14  Should have a keen eye for anomalies and data ...   \n",
       "15  Experience with globalization & aptitude to ex...   \n",
       "16  About the role:Data Analyst is an Individual C...   \n",
       "17  Roles and Responsibilities Interpret data, ana...   \n",
       "18  As a core activity they provide business insig...   \n",
       "19  Knowledge of database query language (Redshift...   \n",
       "\n",
       "                          location  \n",
       "0              Bangalore/Bengaluru  \n",
       "1              Bangalore/Bengaluru  \n",
       "2              Bangalore/Bengaluru  \n",
       "3              Bangalore/Bengaluru  \n",
       "4   Bangalore/Bengaluru, Karnataka  \n",
       "5     Bangalore/Bengaluru(Arekere)  \n",
       "6              Bangalore/Bengaluru  \n",
       "7              Bangalore/Bengaluru  \n",
       "8                           Remote  \n",
       "9              Bangalore/Bengaluru  \n",
       "10             Bangalore/Bengaluru  \n",
       "11             Bangalore/Bengaluru  \n",
       "12    Chennai, Bangalore/Bengaluru  \n",
       "13             Bangalore/Bengaluru  \n",
       "14             Bangalore/Bengaluru  \n",
       "15             Bangalore/Bengaluru  \n",
       "16             Bangalore/Bengaluru  \n",
       "17                          Remote  \n",
       "18             Bangalore/Bengaluru  \n",
       "19             Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.naukri.com/\"\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "search_field_designation=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input \") #job search bar\n",
    "search_field_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input') #location search bar\n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "name = []\n",
    "designation = []\n",
    "company = []\n",
    "skills = []\n",
    "location = []\n",
    "\n",
    "# fetching Names\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "    name.append(i.text)\n",
    "    \n",
    "# fetching Designation\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    designation.append(i.text)\n",
    "\n",
    "# fetching Company names\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "    company.append(i.text)\n",
    "    \n",
    "# fetching  Skills\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='job-description fs12 grey-text']\"):\n",
    "    try:\n",
    "        if i.text == \"Not Specified\": raise NoSuchElementException\n",
    "        skills.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        skills.append('-')\n",
    "                \n",
    "# fetching Locations\n",
    "for i in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "# Creating a dataframe\n",
    "jobs=pd.DataFrame()\n",
    "jobs['Name']=name\n",
    "jobs['Job-designation']=designation\n",
    "jobs['Company_name']=company\n",
    "jobs['skill required']=skills\n",
    "jobs['location']=location\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bbd09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5641b0b4",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bde46c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volume_sold = []\n",
    "Publisher = []\n",
    "Genre = []\n",
    "\n",
    "try: # Scraping Book name\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[2]\"):\n",
    "        Book_name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Author name\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[3]\"):\n",
    "        Author_name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "        \n",
    "try: # Scraping Volume sold\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[4]\"):\n",
    "        Volume_sold.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Publisher\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[5]\"):\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\") \n",
    "    \n",
    "try: # Scraping Genre\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[6]\"):\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "# Creating data frame \n",
    "Books=pd.DataFrame({'Book Name': Book_name, 'Author Name': Author_name, 'Volume Sold': Volume_sold,\n",
    "                    'Publisher': Publisher, 'Genre' : Genre})\n",
    "Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c62726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "944bc4c4",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6937a0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,957,027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>966,723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>932,204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>279,095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>239,273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>47,813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>58,537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>185,825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>39,344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>222,132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  1,957,027  \n",
       "1    51 min     8.7    966,723  \n",
       "2    44 min     8.1    932,204  \n",
       "3    60 min     7.5    279,095  \n",
       "4    43 min     7.6    239,273  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     47,813  \n",
       "96   50 min     7.8     58,537  \n",
       "97   42 min     8.1    185,825  \n",
       "98   45 min     7.1     39,344  \n",
       "99  572 min     8.6    222,132  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "name = []\n",
    "year = []\n",
    "genre = []\n",
    "runtime = []\n",
    "rating = []\n",
    "vote = []\n",
    "\n",
    "try: # Scraping Name\n",
    "    for i in driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\"):\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Year span\n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "        year.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "        \n",
    "try: # Scraping Genre\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p/span[5]\"):\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Run time\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p/span[3]\"):\n",
    "        runtime.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\") \n",
    "    \n",
    "try: # Scraping Ratings\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\"):\n",
    "        rating.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping votes\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\"):\n",
    "        vote.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "\n",
    "# Creating a dataframe \n",
    "imdb=pd.DataFrame({'Name':name, 'Year Span':year, 'Genre':genre, 'Run Time':runtime, 'Ratings':rating, 'Votes':vote})\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e236e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "747efb60",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74f777ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Default Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of atrributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type          Default Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No of instances No of atrributes   Year  \n",
       "0    Categorical, Integer, Real            4177                8   1995   \n",
       "1          Categorical, Integer           48842               14   1996   \n",
       "2    Categorical, Integer, Real             798               38          \n",
       "3                   Categorical           37711              294   1998   \n",
       "4    Categorical, Integer, Real             452              279   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "617               Integer, Real           75840              525   2020   \n",
       "618               Integer, Real             400               50   2020   \n",
       "619                                        1014                7   2020   \n",
       "620                        Real           10129               16   2021   \n",
       "621                        Real            4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "respository=driver.find_element_by_xpath(\"//span[@class='normal']/b/a\")\n",
    "respository.click()\n",
    "    \n",
    "Name=[]\n",
    "Type=[]\n",
    "Task=[]\n",
    "Attribute=[]\n",
    "No_of_Instance=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]\n",
    "\n",
    "# Scrapping data for dataset name\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "    for i in names:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "    \n",
    "# Scrapping data for data type\n",
    "try:\n",
    "    types=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in types[1:]:\n",
    "        Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Type.append('-')\n",
    "    \n",
    "# Scrapping data for default task\n",
    "try:\n",
    "    task=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]\")\n",
    "    for i in task[1:]:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('-')\n",
    "        \n",
    "# Scrapping data for attribute type\n",
    "try:\n",
    "    attribute=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]\")\n",
    "    for i in attribute[1:]:\n",
    "        Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute.append('-')\n",
    "       \n",
    "# Scrapping data for number of instances\n",
    "try:\n",
    "    instance=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]\")\n",
    "    for i in instance[1:]:\n",
    "        No_of_Instance.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instance.append('-')\n",
    "        \n",
    "# Scrapping data for number of attributes\n",
    "try:\n",
    "    attribute_no=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]\")\n",
    "    for i in attribute_no[1:]:\n",
    "        No_of_Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('-')\n",
    "        \n",
    "# Scrapping data for the year details\n",
    "try:\n",
    "    year=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]\")\n",
    "    for i in year[1:]:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('-')\n",
    "    \n",
    "# Creating the dataframe\n",
    "df=pd.DataFrame({\"Dataset Name\":Name, \"Data Type\":Type, \"Default Task\":Task, \"Attribute Type\":Attribute, \n",
    "                 \"No of instances\":No_of_Instance, \"No of atrributes\":No_of_Attribute, \"Year\":Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198826eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
